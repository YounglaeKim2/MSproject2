# Azure OpenAI êµ¬í˜„ ê³„íš (ë°±ì—…/í”„ë¡œë•ì…˜ìš©)

ğŸ“… **ì‘ì„±ì¼**: 2025ë…„ 7ì›” 29ì¼  
ğŸ¯ **ìš©ë„**: Google Gemini ì´í›„ í”„ë¡œë•ì…˜/ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ êµ¬ì¶•ìš©

---

## ğŸ† Azure OpenAI ì¥ì 

### **vs Google Gemini ë¹„êµ**

| í•­ëª© | **Azure OpenAI** | Google Gemini |
|------|------------------|---------------|
| **ë³´ì•ˆ** | â­â­â­â­â­ | â­â­â­â­ |
| **ì•ˆì •ì„±** | â­â­â­â­â­ | â­â­â­ |
| **ê¸°ì—…ìš©** | â­â­â­â­â­ | â­â­â­ |
| **ë¹„ìš©** | â­â­â­ | â­â­â­â­â­ |
| **í•œêµ­ì–´** | â­â­â­â­ | â­â­â­â­â­ |

---

## ğŸ”§ **Azure ë¦¬ì†ŒìŠ¤ ì„¤ì • ê°€ì´ë“œ**

### **Step 1: ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ìƒì„±**
```
ì´ë¦„: MSProject2-SAJU-RG
ì§€ì—­: Korea Central
íƒœê·¸: Project=SAJU, Environment=Production
```

### **Step 2: Azure OpenAI ì„œë¹„ìŠ¤ ìƒì„±**
```
ì„œë¹„ìŠ¤ëª…: saju-openai-service
ì§€ì—­: Korea Central
ê°€ê²© ì±…ì •: Standard S0
```

### **Step 3: ëª¨ë¸ ë°°í¬**
```
ëª¨ë¸: gpt-4o (ì¶”ì²œ) ë˜ëŠ” gpt-35-turbo
ë°°í¬ ì´ë¦„: saju-gpt4
ë²„ì „: ìµœì‹ 
í† í° ì œí•œ: 80K TPM (ë¶„ë‹¹ í† í°)
```

---

## ğŸ’» **ì½”ë“œ êµ¬í˜„**

### **í™˜ê²½ ì„¤ì •**
```bash
pip install openai azure-identity python-dotenv
```

### **í™˜ê²½ ë³€ìˆ˜**
```bash
# .env
AZURE_OPENAI_API_KEY=your_azure_key
AZURE_OPENAI_ENDPOINT=https://saju-openai-service.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=saju-gpt4
AZURE_OPENAI_API_VERSION=2024-02-01
```

### **Azure OpenAI í´ë¼ì´ì–¸íŠ¸**
```python
# app/services/azure_ai_interpreter.py
from openai import AzureOpenAI
import os

class AzureAIInterpreter:
    def __init__(self):
        self.client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        self.deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
    
    async def interpret_saju(self, analysis_result, question, context=None):
        """ì‚¬ì£¼ ë¶„ì„ ê²°ê³¼ë¥¼ AIë¡œ í•´ì„"""
        prompt = self._create_saju_prompt(analysis_result, question, context)
        
        try:
            response = self.client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì „ë¬¸ ëª…ë¦¬í•™ìì…ë‹ˆë‹¤. ì „í†µ ëª…ë¦¬í•™ ì´ë¡ ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•´ì„ì„ ì œê³µí•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=1000,
                top_p=0.9
            )
            
            return {
                "success": True,
                "ai_interpretation": response.choices[0].message.content,
                "usage": response.usage.dict(),
                "model": self.deployment_name
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "fallback": "í˜„ì¬ AI í•´ì„ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤."
            }
    
    def _create_saju_prompt(self, analysis, question, context):
        base_prompt = f"""
        ì‚¬ì£¼ ë¶„ì„ ê²°ê³¼:
        - ì‚¬ì£¼íŒ”ì: {analysis.get('palja', {})}
        - ì˜¤í–‰ ë¶„ì„: {analysis.get('wuxing', {})}
        - ì„±ê²© ë¶„ì„: {analysis.get('personality', {})}
        - ì‹­ì„± ë¶„ì„: {analysis.get('ten_stars', {})}
        
        ì‚¬ìš©ì ì§ˆë¬¸: {question}
        ë¶„ì„ ì˜ì—­: {context or 'ì „ì²´'}
        
        ìœ„ ì‚¬ì£¼ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ í•´ì„í•´ì£¼ì„¸ìš”.
        êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
        """
        return base_prompt
```

### **API ì—”ë“œí¬ì¸íŠ¸**
```python
# app/api/saju.pyì— ì¶”ê°€
from app.services.azure_ai_interpreter import AzureAIInterpreter

@router.post("/ai-chat")
async def ai_chat_interpretation(
    birth_info: BirthInfoRequest,
    question: str = Query(..., description="ì‚¬ìš©ì ì§ˆë¬¸"),
    context: str = Query(None, description="ë¶„ì„ ì˜ì—­")
):
    """Azure OpenAI ê¸°ë°˜ ì‚¬ì£¼ í•´ì„"""
    try:
        # ê¸°ì¡´ ì‚¬ì£¼ ë¶„ì„
        analyzer = SajuAnalyzer()
        analysis_result = analyzer.analyze_saju(birth_info)
        
        # Azure AI í•´ì„
        ai_interpreter = AzureAIInterpreter()
        ai_result = await ai_interpreter.interpret_saju(
            analysis_result, question, context
        )
        
        return {
            "success": True,
            "data": {
                "ai_interpretation": ai_result,
                "analysis_context": analysis_result,
                "timestamp": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## ğŸ’° **ë¹„ìš© ê³„ì‚°**

### **ì˜ˆìƒ ì‚¬ìš©ëŸ‰ (ì›”ê°„)**
- ì‚¬ìš©ì 100ëª… Ã— ë¶„ì„ 3íšŒ = 300íšŒ
- í‰ê·  í† í°: 1,500 í† í°/ìš”ì²­
- ì´ í† í°: 450,000 í† í°/ì›”

### **gpt-4o ê¸°ì¤€**
- ì…ë ¥: $0.0025/1K í† í°
- ì¶œë ¥: $0.01/1K í† í°
- **ì›” ì˜ˆìƒ ë¹„ìš©**: ì•½ $5-7

### **gpt-35-turbo ê¸°ì¤€**
- ì…ë ¥: $0.0005/1K í† í°  
- ì¶œë ¥: $0.0015/1K í† í°
- **ì›” ì˜ˆìƒ ë¹„ìš©**: ì•½ $1-2

---

## ğŸ” **ë³´ì•ˆ ë° ê±°ë²„ë„ŒìŠ¤**

### **ë°ì´í„° ë³´í˜¸**
- Azure Private Link ì„¤ì •
- VNET í†µí•©
- í‚¤ ìê²© ì¦ëª… ëª¨ìŒ ì‚¬ìš©

### **ëª¨ë‹ˆí„°ë§**
- Azure Monitor ì„¤ì •
- Application Insights ì—°ë™
- ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì•Œë¦¼

---

## ğŸ“ˆ **ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš**

### **Google Gemini â†’ Azure OpenAI**

1. **í™˜ê²½ ë³€ìˆ˜ë§Œ ë³€ê²½**
2. **í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ êµì²´**
3. **í”„ë¡¬í”„íŠ¸ ìµœì í™”**
4. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**

### **ì ì§„ì  ì „í™˜**
```python
# í•˜ì´ë¸Œë¦¬ë“œ AI í´ë¼ì´ì–¸íŠ¸
class HybridAIInterpreter:
    def __init__(self):
        self.gemini_client = GeminiAIInterpreter()
        self.azure_client = AzureAIInterpreter()
        self.use_azure = os.getenv("USE_AZURE_AI", "false").lower() == "true"
    
    async def interpret_saju(self, *args, **kwargs):
        if self.use_azure:
            return await self.azure_client.interpret_saju(*args, **kwargs)
        else:
            return await self.gemini_client.interpret_saju(*args, **kwargs)
```

---

## ğŸ¯ **ì–¸ì œ Azureë¡œ ì „í™˜í• ê¹Œ?**

### **ì „í™˜ ì‹œì **
- ì›” ì‚¬ìš©ì 500ëª… ì´ˆê³¼
- ì—”í„°í”„ë¼ì´ì¦ˆ ê³ ê° í™•ë³´
- ë†’ì€ ê°€ìš©ì„± ìš”êµ¬ì‚¬í•­
- ê·œì œ ì¤€ìˆ˜ í•„ìš”

### **ì „í™˜ ì¥ì **
- 99.9% SLA ë³´ì¥
- ê¸°ì—…ê¸‰ ë³´ì•ˆ
- ì „ìš© ì¸ìŠ¤í„´ìŠ¤
- 24/7 ì§€ì›

---

**ğŸŠ ê²°ë¡ : Google Geminië¡œ ì‹œì‘ â†’ ì„±ì¥ ì‹œ Azureë¡œ ì—…ê·¸ë ˆì´ë“œ**